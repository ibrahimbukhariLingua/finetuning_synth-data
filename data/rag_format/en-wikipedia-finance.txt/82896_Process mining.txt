Process mining


# Process mining



**Process mining** is a family of techniques for analyzing event data to understand and improve operational processes. Part of the fields of data science and process management, process mining is generally built on logs that contain case id, a unique identifier for a particular process instance; an activity, a description of the event that is occurring; a timestamp; and sometimes other information such as resources, costs, and so on.

There are three main classes of process mining techniques: *process discovery*, *conformance checking*, and *process enhancement*. In the past, terms like *workflow mining* and *automated business process discovery* (ABPD) were used.


## Overview

Process mining techniques are often used when no formal description of the process can be obtained by other approaches, or when the quality of existing documentation is questionable. For example, application of process mining methodology to the audit trails of a workflow management system, the transaction logs of an enterprise resource planning system, or the electronic patient records in a hospital can result in models describing processes of organizations. Event log analysis can also be used to compare event logs with *prior* model(s) to understand whether the observations conform to a prescriptive or descriptive model. It is required that the event logs data be linked to a case ID, activities, and timestamps.

Contemporary management trends such as BAM (business activity monitoring), BOM (business operations management), and BPI (business process intelligence) illustrate the interest in supporting diagnosis functionality in the context of business process management technology (e.g., workflow management systems and other *process-aware* information systems). Process mining is different from mainstream machine learning, data mining, and artificial intelligence techniques. For example, process discovery techniques in the field of process mining try to discover end-to-end process models that are able to describe sequential, choice relation, concurrent and loop behavior. Conformance checking techniques are closer to optimization than to traditional learning approaches. However, process mining can be used to generate machine learning, data mining, and artificial intelligence problems. After discovering a process model and aligning the event log, it is possible to create basic supervised and unsupervised learning problems. For example, to predict the remaining processing time of a running case or to identify the root causes of compliance problems.

The IEEE Task Force on Process Mining was established in October 2009 as part of the IEEE Computational Intelligence Society. This is a vendor-neutral organization aims to promote the research, development, education and understanding of process mining, make end-users, developers, consultants, and researchers aware of the state-of-the-art in process mining, promote the use of process mining techniques and tools and stimulate new applications, play a role in standardization efforts for logging event data (e.g., XES), organize tutorials, special sessions, workshops, competitions, panels, and develop material (papers, books, online courses, movies, etc.) to inform and guide people new to the field. The IEEE Task Force on Process Mining established the International Process Mining Conference (ICPM) series, lead the development of the IEEE XES standard for storing and exchanging event data, and wrote the Process Mining Manifesto which was translated into 16 languages.


## History and place in data science

The term "process mining" was coined in a research proposal written by the Dutch computer scientist Wil van der Aalst. By 1999, this new field of research emerged under the umbrella of techniques related to data science and process science at the Eindhoven University. In the early days, process mining techniques were often convoluted with the techniques used for workflow management. In 2000, the first practically applicable algorithm for process discovery, "Alpha miner" was developed. The very next year, in 2001, a much similar algorithm based on heuristics called "Heuristic miner" was introduced in the research papers. Further along the link more powerful algorithms such as inductive miner were developed for process discovery. As the field of process mining began to evolve, conformance checking became an integral part of it. The year 2004 earmarked the development of "Token-based replay" for conformance checking purposes. Apart from the mainstream techniques of process discovery and conformance checking, process mining branched out into multiple areas leading to the discovery and development of "performance analysis", "decision mining" and "organizational mining" in the year 2005 and 2006 respectively. In the year 2007, the first-ever commercial process mining company "Futura Pi" was established. The "IEEE task force on PM", a governing body was formed in the year 2009 that began to overlook the norms and standards related to process mining. Further techniques were developed for conformance checking which led to the publishing of "Alignment-based conformance checking" in the year 2010. In 2011, the first-ever process mining book was published. Further along in 2014, a MOOC course was offered by Coursera on process mining. By the year 2018, nearly 30+ commercially available process mining tools were in the picture. The year 2019 earmarked the first process mining conference. Today we have over 35 vendors offering tools and techniques for process discovery and conformance checking.

Process mining should be viewed as a bridge between data science and process science. Process mining focuses on transforming event log into a meaningful representation of the process which can lead to the formation of several data science and machine learning related problems.


## Categories

There are three categories of process mining techniques.

* ***Process discovery***: The first step in process mining. The main goal of process discovery is to transform the event log into a process model. An event log can come from any data storage system that records the activities in an organisation along with the timestamps for those activities. Such an event log is required to contain a case id (a unique identifier to recognise the case to which activity belongs), activity description (a textual description of the activity executed), and timestamp of the activity execution. The result of process discovery is generally a process model which is representative of the event log. Such a process model can be discovered, for example, using techniques such as alpha algorithm (a didactically driven approach), heuristic miner, or inductive miner. Many established techniques exist for automatically constructing process models (for example, Petri nets, BPMN diagrams, activity diagrams, State diagrams, and EPCs) based on an event log. Recently, process mining research has started targeting other perspectives (e.g., data, resources, time, etc.). One example is the technique described in (Aalst, Reijers, & Song, 2005), which can be used to construct a social network. Nowadays, techniques such as "streaming process mining" are being developed to work with continuous online data that has to be processed on the spot.
* ***Conformance checking***: Helps in comparing an event log with an existing process model to analyse the discrepancies between them. Such a process model can be constructed manually or with the help of a discovery algorithm. For example, a process model may indicate that purchase orders of more than 1 million euros require two checks. Another example is the checking of the so-called "four-eyes" principle. Conformance checking may be used to detect deviations (compliance checking), or evaluate the discovery algorithms, or enrich an existing process model. An example is the extension of a process model with performance data, i.e., some *a priori* process model is used to project the potential bottlenecks. Another example is the *decision miner* described in (Rozinat & Aalst, 2006b), which takes an *a priori* process model and analyses every choice in the process model. The event log is consulted for each option to see which information is typically available the moment the choice is made. Conformance checking has various techniques such as "token-based replay", "streaming conformance checking" that are used depending on the system needs.Then classical data mining techniques are used to see which data elements influence the choice. As a result, a decision tree is generated for each choice in the process.
* ***Performance analysis***: Used when there is an *a priori* model. The model is extended with additional performance information such as processing times, cycle times, waiting times, costs, etc., so that the goal is *not* to check conformance, but rather to improve the performance of the existing model with respect to certain process performance measures. An example is the extension of a process model with performance data, i.e., some prior process model dynamically annotated with performance data. It is also possible to extend process models with additional information such as decision rules and organisational information (e.g., roles).

## Process mining software

Process mining software helps organizations analyze and visualize their business processes based on data extracted from various sources, such as transaction logs or event data. This software can identify patterns, bottlenecks, and inefficiencies within a process, enabling organizations to improve their operational efficiency, reduce costs, and enhance their customer experience.

