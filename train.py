# import os
# os.environ["CUDA_VISIBLE_DEVICES"] = "1"
import argparse
import numpy as np
from tqdm import tqdm
import torch
from tabulate import tabulate
from peft import LoraConfig
from transformers import AutoModelForCausalLM, AutoTokenizer
from trl import SFTConfig, SFTTrainer, DataCollatorForCompletionOnlyLM
from datasets import load_from_disk

from util import Data_to_hf



# ================================ FINETUNING CLASS ================================ # 

class Finetune_w_checkpoint():
    
    def __init__(self, **kwargs):
        
        # Extract parameters from kwargs
        ft_data_dir = kwargs.get("ft_data_dir")
        model_name = kwargs.get("model_name")
        self.ft_model_name = kwargs.get("ft_model_name")

        # Parameter Check
        if not all([ft_data_dir, model_name, self.ft_model_name]):
            raise ValueError("Missing required parameters: 'ft_data_dir', 'model_name', or 'ft_model_name'.")

        # Initialize Model and Tokenizer
        self.model = AutoModelForCausalLM.from_pretrained(
            model_name,
            torch_dtype=torch.bfloat16,
            device_map="auto",
            attn_implementation="flash_attention_2",
        )
        self.model.config.use_cache = False
        self.tokenizer = AutoTokenizer.from_pretrained(
            model_name, 
            padding_side="left",
            local_files_only=True,
            trust_remote_code=True
            )

        # Load finetune scripts from the directory
        self.dataset = load_from_disk(ft_data_dir)
        
        # Get the Maximum Sequence Length from dataset
        self.max_seq_length = self.get_max_seq_length_from_chat_dataset(self.dataset, self.tokenizer)

        # Compute the interval of steps to be checkpointed
        total_steps = self.compute_total_steps(len(self.dataset))
        save_steps = (total_steps // 4)+1

        # Initialize LoRA and Tuning configuration
        self.peft_config, self.args = self.lora_config_and_args(
            ft_model_name=self.ft_model_name,
            max_seq_length=self.max_seq_length,
            save_steps=save_steps
        )

    # -------------------- HELPER FUNCTIONS -------------------- #
    
    def compute_total_steps(self, num_samples, batch_size=1, gradient_accumulation_steps=8, epochs=1):
        steps_per_epoch = (num_samples // batch_size) // gradient_accumulation_steps
        return steps_per_epoch * epochs

    def printTrainer(self, trainer, tokenizer):
        train_dataloader = trainer.get_train_dataloader()
        for batch_data in train_dataloader:
            input_ids = batch_data['input_ids'][0]
            attention_mask = batch_data['attention_mask'][0]
            label_ids = batch_data['labels'][0]

            tokens = tokenizer.convert_ids_to_tokens(input_ids)
            decoded = tokenizer.decode(input_ids, skip_special_tokens=False)

            print("Tokens:")
            for i, token in enumerate(tokens):
                attn = attention_mask[i].item()
                label_id = label_ids[i].item()
                label_token = tokenizer.convert_ids_to_tokens([label_id])[0] if label_id != -100 else 'IGN'
                print(f"{i:2d}: {token:12s} | Label_id: {label_id} | Attention: {attn} | Label: {label_token}")

            print("\nDecoded sentence:")
            print(decoded)
            break

    def get_max_seq_length_from_chat_dataset(self, dataset, tokenizer, instruction_template="<|im_start|>user\n", response_template="<|im_start|>assistant\n", percentile=97, verbose=True):    
        input_lengths = []
        for example in tqdm(dataset, desc="Tokenizing chat examples"):
            messages = example["messages"]
            full_text = ""
            for message in messages:
                role = message["role"]
                content = message["content"]
                if role == "system":
                    full_text += f"<|im_start|>system\n{content}<|im_end|>\n"
                elif role == "user":
                    full_text += f"{instruction_template}{content}<|im_end|>\n"
                elif role == "assistant":
                    full_text += f"{response_template}{content}<|im_end|>\n"
                else:
                    raise ValueError(f"Unsupported role: {role}")

            tokens = tokenizer(full_text, add_special_tokens=False, truncation=False)["input_ids"]
            input_lengths.append(len(tokens))

        if verbose:
            stats = [
                ["Min", np.min(input_lengths)],
                ["Max", np.max(input_lengths)],
                ["Mean", f"{np.mean(input_lengths):.2f}"],
                ["Median", np.median(input_lengths)],
                [f"{percentile}th Percentile", np.percentile(input_lengths, percentile)]
            ]
            print("\nðŸ“Š Chat Token Stats:\n")
            print(tabulate(stats, headers=["Metric", "Value"], tablefmt="github"))

        return int(np.percentile(input_lengths, percentile))

    # -------------------- CONFIG FUNCTION -------------------- #

    def lora_config_and_args(self, ft_model_name, max_seq_length, rank_dimension=4, lora_alpha=8, lora_dropout=0.05, save_steps=100):
        peft_config = LoraConfig(
            r=rank_dimension,
            lora_alpha=lora_alpha,
            lora_dropout=lora_dropout,
            bias="none",
            target_modules="all-linear",
            task_type="CAUSAL_LM",
        )

        args = SFTConfig(
            max_seq_length=max_seq_length,
            output_dir=f"Models/{ft_model_name}",
            num_train_epochs=1,
            per_device_train_batch_size=1,
            gradient_accumulation_steps=8,
            gradient_checkpointing=True,
            optim="adamw_torch_fused",
            learning_rate=2e-4,
            max_grad_norm=0.3,
            warmup_ratio=0.03,
            lr_scheduler_type="constant",
            logging_steps=10,
            save_strategy="steps",              # Save based on step count
            save_steps=save_steps,              # Save at halfway point
            bf16=True
        )

        return peft_config, args

    # -------------------- MAIN FUNCTION -------------------- #

    def run(self, ft_w_lora:bool):
        collator = DataCollatorForCompletionOnlyLM(
            instruction_template="<|im_start|>user\n",
            response_template="<|im_start|>assistant\n",
            tokenizer=self.tokenizer,
            mlm=False
        )

        if ft_w_lora == True:
            trainer = SFTTrainer(
                model=self.model,
                args=self.args,
                train_dataset=self.dataset,
                peft_config=self.peft_config,
                processing_class=self.tokenizer,
                data_collator=collator,
            )
        else:
            trainer = SFTTrainer(
                model=self.model,
                args=self.args,
                train_dataset=self.dataset,
                processing_class=self.tokenizer,
                data_collator=collator,
            )

        self.printTrainer(trainer, self.tokenizer)
        
        trainer.train()




if __name__ == "__main__":
    
    # # Processing the datasets beforehand
    # data_to_hf = Data_to_hf(directory_path="data/training/synth_wiki_finance_v2.2", 
    #                         num_of_samples=1000, 
    #                         add_cite=True, 
    #                         add_think=True)
    # dataset = data_to_hf.run(save_dir="data/finetuning_datasets/cite_think_v2.2")
    
    # # Processing the datasets before hand
    # data_to_hf = Data_to_hf(directory_path="data/training/synth_wiki_finance_v2.2", 
    #                         num_of_samples=1000, 
    #                         add_cite=False, 
    #                         add_think=True)
    # dataset = data_to_hf.run(save_dir="data/finetuning_datasets/think_v2.2")
    
    # # Processing the datasets before hand
    # data_to_hf = Data_to_hf(directory_path="data/training/synth_wiki_finance_v2.2", 
    #                         num_of_samples=1000, 
    #                         add_cite=True, 
    #                         add_think=False)
    # dataset = data_to_hf.run(save_dir="data/finetuning_datasets/cite_v2.2")
    
    parser = argparse.ArgumentParser(description="Fine-tune a model with checkpoint support.")

    parser.add_argument('--ft_data_dir', type=str, required=True, help='Path to the fine-tuning data directory.')
    parser.add_argument('--model_name', type=str, required=True, help='Base model name to fine-tune.')
    parser.add_argument('--ft_model_name', type=str, required=True, help='Name to assign to the fine-tuned model.')
    parser.add_argument('--ft_w_lora', action='store_true', help='Whether to fine-tune with LoRA.')

    args = parser.parse_args()

    kwargs = {
        'ft_data_dir': args.ft_data_dir,
        'model_name': args.model_name,
        'ft_model_name': args.ft_model_name,
    }

    ft_trainer = Finetune_w_checkpoint(**kwargs)
    ft_trainer.run(ft_w_lora=args.ft_w_lora)